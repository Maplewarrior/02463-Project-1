{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756dc76c",
   "metadata": {},
   "source": [
    "# Project 1 in course 02463\n",
    "\n",
    "## Implementing Bayesian optimization for a CNN as a means to find optimal hyperparameters\n",
    "\n",
    "### The code for the CNN was heavily inspired by the following kaggle article:\n",
    "#### https://www.kaggle.com/mirhyun0508/2022-smarcle-ai-fashion-mnist-cnn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877e0bd",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "560cae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential\n",
    "\n",
    "import GPyOpt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e38088cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Data/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('Data/fashion-mnist_test.csv')\n",
    "\n",
    "class_names = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "072bf046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 359.3 MB\n"
     ]
    }
   ],
   "source": [
    "train.head()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ac5a47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop([\"label\"], axis=1)\n",
    "Y_train = train[\"label\"]\n",
    "\n",
    "X_test = test.drop([\"label\"], axis=1)\n",
    "Y_test = test[\"label\"]\n",
    "\n",
    "X_train = X_train.to_numpy()\n",
    "Y_train = Y_train.to_numpy()\n",
    "\n",
    "X_test = X_test.to_numpy()\n",
    "Y_test = Y_test.to_numpy()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e2f71f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display an image\n",
    "plt.imshow(X_train[0], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c1b47777",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b947be",
   "metadata": {},
   "source": [
    "### Defining CNN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1d5ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, X_train, Y_train, X_test, Y_test):\n",
    "        #self.n_epochs = n_epochs\n",
    "        #self.kernel_size = kernel_size\n",
    "        #self.learning_rate = learning_rate\n",
    "        #self.batch_size = batch_size\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        \n",
    "        \n",
    "        \n",
    "    def CNNModelTrain(self, n_epochs, batch_size, kernel_size, learning_rate, summary = False):\n",
    "        \n",
    "        # The model is created\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(kernel_size, kernel_size) , input_shape = (28, 28, 1), activation='relu'))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate = learning_rate), metrics=['accuracy'])\n",
    "        \n",
    "        # Display model summary if true\n",
    "        if summary == True:\n",
    "            model.summary()\n",
    "        \n",
    "        # Train the model\n",
    "        #MODEL_DIR = './model/'\n",
    "        #if not os.path.exists(MODEL_DIR):\n",
    "        #  os.mkdir(MODEL_DIR)\n",
    "\n",
    "        #modelpath='./model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "        #checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "        #early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "        \n",
    "        history = model.fit(X_train, Y_train, \n",
    "        validation_data=(X_test, Y_test), epochs=n_epochs, \n",
    "        batch_size= batch_size, verbose=1)\n",
    "        #callbacks=[early_stopping_callback, checkpointer])\n",
    "        \n",
    "        accuracies = history.history['val_accuracy']\n",
    "        return history, accuracies[-1]\n",
    "    \n",
    "    \n",
    "    def plotResults(self, history):\n",
    "        y_vacc = history.history['val_accuracy']\n",
    "\n",
    "        y_acc = history.history['accuracy']\n",
    "\n",
    "\n",
    "        x_len = np.arange(1,len(y_acc)+1, 1)\n",
    "        plt.plot(x_len, y_vacc, marker='.', c='red', label='Testset_accuracy')\n",
    "        plt.plot(x_len, y_acc, marker='.', c='blue', label='Trainset_accuracy')\n",
    "\n",
    "\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.grid()\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.show()\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08bfe30",
   "metadata": {},
   "source": [
    "### Create a model and train with fixed hyperparameters (deliberately bad)\n",
    "#### The train-test dynamics are illustrated\n",
    "##### Train and test accuracy is also visualized below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c58241fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 7744)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 128)               991360    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,011,978\n",
      "Trainable params: 1,011,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "150/150 [==============================] - ETA: 0s - loss: 1.0009 - accuracy: 0.7358\n",
      "Epoch 00001: val_loss improved from inf to 0.40801, saving model to ./model\\01-0.4080.hdf5\n",
      "150/150 [==============================] - 64s 424ms/step - loss: 1.0009 - accuracy: 0.7358 - val_loss: 0.4080 - val_accuracy: 0.8490\n",
      "Epoch 2/2\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.4813 - accuracy: 0.8225\n",
      "Epoch 00002: val_loss improved from 0.40801 to 0.37954, saving model to ./model\\02-0.3795.hdf5\n",
      "150/150 [==============================] - 63s 421ms/step - loss: 0.4813 - accuracy: 0.8225 - val_loss: 0.3795 - val_accuracy: 0.8591\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at the last epoch: 0.8590999841690063\n",
      "Loss at the last epoch: 0.37954336404800415\n"
     ]
    }
   ],
   "source": [
    "# If you want the model to perform well set lr = 0.001 and k = 3.\n",
    "\n",
    "# Keep these values fixed if you want a decent but improvable result:\n",
    "## e = 5, lr = 0.05, k = 5, b = 400\n",
    "e = 2\n",
    "lr = 0.03\n",
    "k = 5\n",
    "b = 400\n",
    "\n",
    "\n",
    "m = CNN(X_train = X_train, Y_train = Y_train, X_test = X_test,Y_test = Y_test)\n",
    "# Create a CNN model\n",
    "hist, final_acc = m.CNNModelTrain(n_epochs = e, batch_size = b, kernel_size = k, learning_rate = lr,summary = True)\n",
    "\n",
    "\n",
    "m.plotResults(hist)\n",
    "\n",
    "\n",
    "final_loss = hist.history['val_loss'][-1]\n",
    "print(\"Accuracy at the last epoch:\", final_acc)\n",
    "print(\"Loss at the last epoch:\", final_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13bd3c",
   "metadata": {},
   "source": [
    "## Implementing Exhaustive Search for finding the optimal hyperparameters\n",
    "\n",
    "### Hyperparameters are defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bdbc1f77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.001, 0.051000000000000004, 0.101)\n",
      "(2, 4, 6, 8, 10)\n",
      "(1, 3, 5)\n",
      "0.001\n",
      "0.051000000000000004\n",
      "0.101\n"
     ]
    }
   ],
   "source": [
    "# Learning rate:\n",
    "lr = tuple(np.arange(0.001, 0.15, 0.05, dtype = np.float64))\n",
    "# Number of epochs\n",
    "n_epochs = tuple(np.arange(2, 12, 2, dtype = np.int64))\n",
    "# Kernel sizes\n",
    "kernel_sizes = tuple(np.arange(1,7,2, dtype = np.int64))\n",
    "# batch sizes\n",
    "batch_sizes = tuple(np.arange(100,500, 100, dtype = np.int64))\n",
    "print(lr)\n",
    "print(n_epochs)\n",
    "print(kernel_sizes)\n",
    "\n",
    "\n",
    "for l in lr:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2955c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "210/600 [=========>....................] - ETA: 1:01 - loss: 0.6470 - accuracy: 0.7725"
     ]
    }
   ],
   "source": [
    "# Record the time taken until convergence\n",
    "start = timer()\n",
    "\n",
    "final_losses = list()\n",
    "final_accs = list()\n",
    "\n",
    "optimal_hyperparams = [0,0,0,0]\n",
    "best_acc = 0\n",
    "\n",
    "\n",
    "for e in n_epochs:\n",
    "    for b in batch_sizes:\n",
    "        for k in kernel_sizes:\n",
    "            for l in lr:\n",
    "                m = CNN(X_train = X_train, Y_train = Y_train, X_test = X_test,Y_test = Y_test)\n",
    "                \n",
    "                # Create CNN model and train it\n",
    "                hist, acc = m.CNNModelTrain(n_epochs = e, batch_size = b, \n",
    "                                        kernel_size = k, learning_rate = l, summary = False)\n",
    "                \n",
    "                final_losses.append(hist.history['val_loss'][-1])\n",
    "                final_accs.append(acc)\n",
    "\n",
    "                if max(final_accs) > best_acc:\n",
    "                    best_acc = max(final_accs)\n",
    "                    optimal_hyperparams = [e, b, k, l]\n",
    "\n",
    "end = timer()\n",
    "print(\"The best accuracy was:\", max(final_accs))\n",
    "print(\"-------------------------------------------\")\n",
    "print(\"The best hyperparameters were found to be:\")\n",
    "print(\"Number of epochs:\", optimal_hyperparams[0])\n",
    "print(\"Batch size:\", optimal_hyperparams[1])\n",
    "print(\"Kernel size:\", optimal_hyperparams[2])\n",
    "print(\"Learning rate:\", optimal_hyperparams[3])\n",
    "\n",
    "print(\"It took\", end-start, \"time until convergence\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Model_Train( kernel_size, learning_rate, n_epochs = 5,batch_size = 300):\n",
    "    \n",
    "    # The model is created\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(int(kernel_size), int(kernel_size)) , input_shape = (28, 28, 1), activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = keras.optimizers.Adam(learning_rate = learning_rate), metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    # Train the model\n",
    "    MODEL_DIR = './model/'\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.mkdir(MODEL_DIR)\n",
    "\n",
    "    modelpath='./model/{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "    history = model.fit(X_train, Y_train, \n",
    "    validation_data=(X_test, Y_test), epochs=n_epochs, \n",
    "    batch_size= batch_size, verbose=1, \n",
    "    callbacks=[early_stopping_callback, checkpointer])\n",
    "\n",
    "    accuracies = history.history['val_accuracy']\n",
    "    return accuracies[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7145fcaa",
   "metadata": {},
   "source": [
    "## Bayesian optimization using GpyOpt\n",
    "\n",
    "#### This code is inspired by code from Exercise 4 in course 02463"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "12e90d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 3.3790 - accuracy: 0.5275\n",
      "Epoch 00001: val_loss improved from inf to 0.75483, saving model to ./model\\01-0.7548.hdf5\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 3.3790 - accuracy: 0.5275 - val_loss: 0.7548 - val_accuracy: 0.6977\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8986 - accuracy: 0.6627\n",
      "Epoch 00002: val_loss improved from 0.75483 to 0.70344, saving model to ./model\\02-0.7034.hdf5\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.8986 - accuracy: 0.6627 - val_loss: 0.7034 - val_accuracy: 0.7258\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8875 - accuracy: 0.6693\n",
      "Epoch 00003: val_loss improved from 0.70344 to 0.62697, saving model to ./model\\03-0.6270.hdf5\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.8875 - accuracy: 0.6693 - val_loss: 0.6270 - val_accuracy: 0.7545\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8290 - accuracy: 0.6902\n",
      "Epoch 00004: val_loss did not improve from 0.62697\n",
      "200/200 [==============================] - 51s 257ms/step - loss: 0.8290 - accuracy: 0.6902 - val_loss: 0.6562 - val_accuracy: 0.7441\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8075 - accuracy: 0.7008\n",
      "Epoch 00005: val_loss improved from 0.62697 to 0.59837, saving model to ./model\\05-0.5984.hdf5\n",
      "200/200 [==============================] - 52s 259ms/step - loss: 0.8075 - accuracy: 0.7008 - val_loss: 0.5984 - val_accuracy: 0.7721\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 4.7736 - accuracy: 0.1007\n",
      "Epoch 00001: val_loss improved from inf to 2.30786, saving model to ./model\\01-2.3079.hdf5\n",
      "200/200 [==============================] - 80s 398ms/step - loss: 4.7736 - accuracy: 0.1007 - val_loss: 2.3079 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3052 - accuracy: 0.0971\n",
      "Epoch 00002: val_loss did not improve from 2.30786\n",
      "200/200 [==============================] - 81s 405ms/step - loss: 2.3052 - accuracy: 0.0971 - val_loss: 2.3093 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3051 - accuracy: 0.1021\n",
      "Epoch 00003: val_loss improved from 2.30786 to 2.30510, saving model to ./model\\03-2.3051.hdf5\n",
      "200/200 [==============================] - 77s 384ms/step - loss: 2.3051 - accuracy: 0.1021 - val_loss: 2.3051 - val_accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3058 - accuracy: 0.1027\n",
      "Epoch 00004: val_loss did not improve from 2.30510\n",
      "200/200 [==============================] - 77s 385ms/step - loss: 2.3058 - accuracy: 0.1027 - val_loss: 2.3062 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3070 - accuracy: 0.0975\n",
      "Epoch 00005: val_loss did not improve from 2.30510\n",
      "200/200 [==============================] - 88s 438ms/step - loss: 2.3070 - accuracy: 0.0975 - val_loss: 2.3058 - val_accuracy: 0.1000\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 9.6031 - accuracy: 0.1013\n",
      "Epoch 00001: val_loss improved from inf to 2.30552, saving model to ./model\\01-2.3055.hdf5\n",
      "200/200 [==============================] - 71s 357ms/step - loss: 9.6031 - accuracy: 0.1013 - val_loss: 2.3055 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3052 - accuracy: 0.0996\n",
      "Epoch 00002: val_loss improved from 2.30552 to 2.30543, saving model to ./model\\02-2.3054.hdf5\n",
      "200/200 [==============================] - 68s 342ms/step - loss: 2.3052 - accuracy: 0.0996 - val_loss: 2.3054 - val_accuracy: 0.1000\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3070 - accuracy: 0.0985\n",
      "Epoch 00003: val_loss did not improve from 2.30543\n",
      "200/200 [==============================] - 81s 404ms/step - loss: 2.3070 - accuracy: 0.0985 - val_loss: 2.3063 - val_accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3065 - accuracy: 0.1000\n",
      "Epoch 00004: val_loss did not improve from 2.30543\n",
      "200/200 [==============================] - 97s 484ms/step - loss: 2.3065 - accuracy: 0.1000 - val_loss: 2.3065 - val_accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.3064 - accuracy: 0.1018\n",
      "Epoch 00005: val_loss improved from 2.30543 to 2.30509, saving model to ./model\\05-2.3051.hdf5\n",
      "200/200 [==============================] - 88s 439ms/step - loss: 2.3064 - accuracy: 0.1018 - val_loss: 2.3051 - val_accuracy: 0.1000\n",
      "Epoch 1/5\n",
      "200/200 [==============================] - ETA: 0s - loss: 2.8851 - accuracy: 0.0994\n",
      "Epoch 00001: val_loss improved from inf to 2.30370, saving model to ./model\\01-2.3037.hdf5\n",
      "200/200 [==============================] - 98s 490ms/step - loss: 2.8851 - accuracy: 0.0994 - val_loss: 2.3037 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "155/200 [======================>.......] - ETA: 18s - loss: 2.3045 - accuracy: 0.0984"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2808/2525050484.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0macquisition_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"EI\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m opt = GPyOpt.methods.BayesianOptimization(f = objective_function,   # function to optimize\n\u001b[0m\u001b[0;32m     32\u001b[0m                                               \u001b[0mdomain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdomain\u001b[0m\u001b[1;33m,\u001b[0m         \u001b[1;31m# box-constrains of the problem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                                               \u001b[0macquisition_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macquisition_func\u001b[0m      \u001b[1;31m# Select acquisition function MPI, EI, LCB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\GPyOpt\\methods\\bayesian_optimization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, domain, constraints, cost_withGradients, model_type, X, Y, initial_design_numdata, initial_design_type, acquisition_type, normalize_Y, exact_feval, acquisition_optimizer_type, model_update_interval, evaluator_type, batch_size, num_cores, verbosity, verbosity_model, maximize, de_duplication, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_design_type\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0minitial_design_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_design_numdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_design_numdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_design_chooser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[1;31m# --- CHOOSE the model type. If an instance of a GPyOpt model is passed (possibly user defined), it is used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\GPyOpt\\methods\\bayesian_optimization.py\u001b[0m in \u001b[0;36m_init_design_chooser\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_design\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_design_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_design_numdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[1;31m# Case 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\GPyOpt\\core\\task\\objective.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_procs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mf_evals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost_evals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\GPyOpt\\core\\task\\objective.py\u001b[0m in \u001b[0;36m_eval_func\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mst_time\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mrlt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mf_evals\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf_evals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrlt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mcost_evals\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mst_time\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2808/2525050484.py\u001b[0m in \u001b[0;36mobjective_function\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN_Model_Train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2808/751297837.py\u001b[0m in \u001b[0;36mCNN_Model_Train\u001b[1;34m(kernel_size, learning_rate, n_epochs, batch_size)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mearly_stopping_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     history = model.fit(X_train, Y_train, \n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "# Same hyperparameters as before:\n",
    "## Learning rate:\n",
    "lr = tuple(np.arange(0.001, 0.15, 0.05, dtype = np.float64))\n",
    "## Number of epochs\n",
    "n_epochs = tuple(np.arange(2, 12, 2, dtype = np.int64))\n",
    "## Kernel sizes\n",
    "kernel_sizes = tuple(np.arange(1,8,2, dtype = np.int64))\n",
    "## batch sizes\n",
    "batch_sizes = tuple(np.arange(100,500, 100, dtype = np.int64))\n",
    "\n",
    "\n",
    "domain = [{'name': 'kernel_sizes', 'type': 'discrete', 'domain': kernel_sizes},\n",
    "          {'name': 'learning_rate', 'type': 'discrete', 'domain': lr},\n",
    "          {'name': 'n_epochs', 'type': 'discrete', 'domain': n_epochs},\n",
    "          {'name': 'batch_sizes', 'type': 'discrete', 'domain': batch_sizes}\n",
    "          ]\n",
    "\n",
    "def objective_function(x):\n",
    "    param = x[0]\n",
    "    \n",
    "    acc = CNN_Model_Train(kernel_size = param[0], learning_rate = param[1])\n",
    "    \n",
    "    return -float(acc)\n",
    "\n",
    "\n",
    "### EI acquisition function ###\n",
    "acquisition_func = \"EI\"\n",
    "\n",
    "opt = GPyOpt.methods.BayesianOptimization(f = objective_function,   # function to optimize\n",
    "                                              domain = domain,         # box-constrains of the problem\n",
    "                                              acquisition_type = acquisition_func      # Select acquisition function MPI, EI, LCB\n",
    "                                             )\n",
    "opt.acquisition.exploration_weight=.1\n",
    "\n",
    "opt.run_optimization(max_iter = 10) \n",
    "\n",
    "x_best = opt.X[np.argmin(opt.Y)]\n",
    "\n",
    "end = timer()\n",
    "print(\"For acquisition_type: {0}\".format(acquisition_func))\n",
    "print(\"time: {0}\".format(end - start))\n",
    "print(\"The best parameters obtained: {0}\".format(x_best))\n",
    "print(\"The accuracy was: {0}\".format(-min(opt.Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e7912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72db45",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MPI acquisition function ###\n",
    "acquisition_func = \"MPI\"\n",
    "\n",
    "opt = GPyOpt.methods.BayesianOptimization(f = objective_function,   # function to optimize\n",
    "                                              domain = domain,         # box-constrains of the problem\n",
    "                                              acquisition_type = acquisition_func      # Select acquisition function MPI, EI, LCB\n",
    "                                             )\n",
    "opt.acquisition.exploration_weight=.1\n",
    "\n",
    "opt.run_optimization(max_iter = 10) \n",
    "\n",
    "x_best = opt.X[np.argmin(opt.Y)]\n",
    "\n",
    "end = timer()\n",
    "print(\"For acquisition_type: {0}\".format(acquisition_func))\n",
    "print(\"time: {0}\".format(end - start))\n",
    "print(\"The best parameters obtained: {0}\".format(x_best))\n",
    "print(\"The loss was: {0}\".format(min(opt.Y)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### MPI acquisition function ###\n",
    "acquisition_func = \"LCB\"\n",
    "\n",
    "opt = GPyOpt.methods.BayesianOptimization(f = objective_function,   # function to optimize\n",
    "                                              domain = domain,         # box-constrains of the problem\n",
    "                                              acquisition_type = acquisition_func      # Select acquisition function MPI, EI, LCB\n",
    "                                             )\n",
    "opt.acquisition.exploration_weight=.1\n",
    "\n",
    "opt.run_optimization(max_iter = 10) \n",
    "\n",
    "x_best = opt.X[np.argmin(opt.Y)]\n",
    "\n",
    "end = timer()\n",
    "print(\"For acquisition_type: {0}\".format(acquisition_func))\n",
    "print(\"time: {0}\".format(end - start))\n",
    "print(\"The best parameters obtained: {0}\".format(x_best))\n",
    "print(\"The loss was: {0}\".format(min(opt.Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a50d030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
