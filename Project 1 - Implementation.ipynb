{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2cbeec",
   "metadata": {},
   "source": [
    "## See the ReadME for a description of the project\n",
    "\n",
    "\n",
    "### Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2905840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "import GPyOpt\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e68c130",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8fa20980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1500, 784) Test data shape: (500, 784)\n",
      "Train labels shape: (1500,)   Test labels shape: (500,)\n"
     ]
    }
   ],
   "source": [
    "# define number of classes\n",
    "n_classes = 10\n",
    "train_size = 1500\n",
    "test_size = 500\n",
    "\n",
    "# load train and test sets\n",
    "train = pd.read_csv('Data/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('Data/fashion-mnist_test.csv')\n",
    "\n",
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "\n",
    "X_train = train[:,1:]\n",
    "y_train = train[:,0]\n",
    "X_test = test[:,1:]\n",
    "y_test = test[:,0]\n",
    "\n",
    "where_train = []\n",
    "where_test = []\n",
    "\n",
    "for label in range(n_classes):\n",
    "    where_train.append(np.where(y_train == label)[0][:round(train_size/10)])\n",
    "    where_test.append(np.where(y_test == label)[0][:round(test_size/10)])\n",
    "\n",
    "where_train = np.array(where_train).flatten()\n",
    "where_test = np.array(where_test).flatten()\n",
    "\n",
    "\n",
    "X_train = X_train[where_train]\n",
    "y_train = y_train[where_train]\n",
    "\n",
    "X_test = X_test[where_test]\n",
    "y_test = y_test[where_test]\n",
    "    \n",
    "print(\"Train data shape:\", X_train.shape, \"Test data shape:\", X_test.shape)\n",
    "print(\"Train labels shape:\", y_train.shape,\"  Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2f090f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([1500, 1, 28, 28]) Test data shape: torch.Size([500, 1, 28, 28])\n",
      "Train labels shape: torch.Size([1500])   Test labels shape: torch.Size([500])\n"
     ]
    }
   ],
   "source": [
    "# this section is inspired by code from the article:\n",
    "# \"Build an Image Classification Model using Convolutional Neural Networks in PyTorch\"\n",
    "# Author: Pulkit Sharma\n",
    "# https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/\n",
    "\n",
    "# change training and test set into tensors\n",
    "X_train = X_train.reshape(len(X_train),1,28,28)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_train = X_train.type(torch.FloatTensor)\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_train = y_train.type(torch.LongTensor)\n",
    "\n",
    "X_test = X_test.reshape(len(X_test),1,28,28)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "X_test = X_test.type(torch.FloatTensor)\n",
    "\n",
    "y_test = y_test.astype(int)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "y_test = y_test.type(torch.LongTensor)\n",
    "\n",
    "# verify shape of training data\n",
    "print(\"Train data shape:\", X_train.shape, \"Test data shape:\", X_test.shape)\n",
    "print(\"Train labels shape:\", y_train.shape,\"  Test labels shape:\", y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e4ca9",
   "metadata": {},
   "source": [
    "## Implementing the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7e98d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section is inspired by code from the article:\n",
    "# \"Build an Image Classification Model using Convolutional Neural Networks in PyTorch\"\n",
    "# Author: Pulkit Sharma\n",
    "# https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/\n",
    "\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self, kernel_size = 2, stride = 1, padding = 1):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        self.cnn_layers = Sequential(\n",
    "            # Define convolutional layers\n",
    "            # input dimensionality before each layer is added\n",
    "            \n",
    "            # 1st layer\n",
    "            # 1x28x28\n",
    "            Conv2d(1,4,kernel_size=kernel_size,stride=stride,padding=padding),\n",
    "            # apply batch normalization\n",
    "            #BatchNorm2d(4),\n",
    "            # activation function ReLU\n",
    "            ReLU(),\n",
    "            # apply pooling\n",
    "            MaxPool2d(kernel_size=kernel_size,stride=stride),\n",
    "            \n",
    "            # second layer\n",
    "            # 4x14x14\n",
    "            #Conv2d(4,4,kernel_size=kernel_size,stride=stride,padding=padding),\n",
    "            #BatchNorm2d(4),\n",
    "            #ReLU(),\n",
    "            #MaxPool2d(kernel_size=kernel_size,stride=stride),\n",
    "            \n",
    "            # 4x7x7\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(4*7*7,n_classes)\n",
    "        )\n",
    "    \n",
    "    def update_linear_layers(self,input_size):\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(input_size,n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.contiguous().view(x.size(0),-1)\n",
    "        self.update_linear_layers(x.size()[1])\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4c0cd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, train_losses, val_losses, criterion):\n",
    "    \"\"\"Train model\n",
    "\n",
    "    Args:\n",
    "        epoch (int): Current epoch (index in loop)\n",
    "        model (obj): Model object\n",
    "        optimizer (obj): optimizer function\n",
    "        train_losses (list): List of train losses\n",
    "        val_losses (list): List of test losses\n",
    "        criterion (func): Criterion function\n",
    "\n",
    "    Returns:\n",
    "        list, list, obj, obj: train losses, test losses, optimizer, model\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    # getting the training set\n",
    "    x_train_t, y_train_t = Variable(X_train), Variable(y_train)\n",
    "    # getting the validation set\n",
    "    x_val_t, y_val_t = Variable(X_test), Variable(y_test)\n",
    "    # converting the data into GPU format\n",
    "    if torch.cuda.is_available():\n",
    "        x_train_t = x_train_t.cuda()\n",
    "        y_train_t = y_train_t.cuda()\n",
    "        x_val_t = x_val_t.cuda()\n",
    "        y_val_t = y_val_t.cuda()\n",
    "\n",
    "    # clearing the Gradients of the model parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # prediction for training and validation set\n",
    "    output_train = model(x_train_t)\n",
    "    output_val = model(x_val_t)\n",
    "\n",
    "    # computing the training and validation loss\n",
    "    loss_train = criterion(output_train, y_train_t)\n",
    "    loss_val = criterion(output_val, y_val_t)\n",
    "    train_losses.append(loss_train)\n",
    "    val_losses.append(loss_val)\n",
    "\n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    #if epoch%2 == 0:\n",
    "    #    # printing the validation loss\n",
    "    #   print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)\n",
    "\n",
    "    return train_losses, val_losses, optimizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8ecac926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CNN_model_train(kernel_size = 2, stride = 1, padding = 1, learning_rate = 0.07, n_epochs = 5):\n",
    "    \"\"\"Define network and train model with given hyperparameters\n",
    "\n",
    "    Args:\n",
    "        kernel_size (int, optional): Kernel size. Defaults to 2.\n",
    "        stride (int, optional): Stride. Defaults to 1.\n",
    "        padding (int, optional): Padding. Defaults to 1.\n",
    "        learning_rate (float, optional): Learning rate. Defaults to 0.07.\n",
    "        n_epochs (int, optional): Number of epochs. Defaults to 5.\n",
    "    \"\"\"\n",
    "    # define model\n",
    "    model = Net(kernel_size, stride, padding)\n",
    "    # defining the optimizer\n",
    "    optimizer = Adam(model.parameters(), lr=0.07)\n",
    "    # defining the loss function\n",
    "    criterion = CrossEntropyLoss()\n",
    "    # checking if GPU is available\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    # defining the number of epochs\n",
    "    # n_epochs = 5\n",
    "    # empty list to store training losses\n",
    "    train_losses = []\n",
    "    # empty list to store validation losses\n",
    "    val_losses = []\n",
    "    # training the model\n",
    "    for epoch in range(n_epochs):\n",
    "        train_losses, val_losses, optimizer, model = train(epoch, model, optimizer, train_losses, val_losses, criterion)\n",
    "    #print(model)\n",
    "    # return final loss value\n",
    "    #print(val_losses[-1])\n",
    "    return val_losses[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5f3ff127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.548709869384766\n"
     ]
    }
   ],
   "source": [
    "# Run model and print the final loss\n",
    "final_loss = CNN_model_train(kernel_size = 2, stride = 1, padding = 1, learning_rate = 0.07, n_epochs = 2)\n",
    "print(float(final_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f416c",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5e90a40f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For acquisition_type: EI\n",
      "time: 10.917514443000982\n",
      "The best parameters obtained: [1.   2.   1.   0.01 6.  ]\n",
      "The loss was: [2.3064599]\n",
      "For acquisition_type: MPI\n",
      "time: 14.103047366001192\n",
      "The best parameters obtained: [2.   1.   1.   0.05 4.  ]\n",
      "The loss was: [3.36552763]\n",
      "For acquisition_type: LCB\n",
      "time: 22.635389376000603\n",
      "The best parameters obtained: [2.   2.   1.   0.03 8.  ]\n",
      "The loss was: [2.28168726]\n"
     ]
    }
   ],
   "source": [
    "# This code is inspired by code from Exercise 4 in course 02463\n",
    "\n",
    "\n",
    "start = timer()\n",
    "\n",
    "kernel_sizes = tuple(np.arange(1,3,1, dtype= np.int))\n",
    "stride = tuple(np.arange(1,3,1, dtype= np.int))\n",
    "padding = tuple(np.arange(1,3,1, dtype= np.int))\n",
    "learning_rate = tuple(np.arange(0.01,0.11, 0.02, dtype= np.float))\n",
    "n_epochs = tuple(np.arange(2,10, 2, dtype= np.int))\n",
    "\n",
    "# # For testing\n",
    "# kernel_sizes = tuple(np.arange(1,2,1, dtype= np.int))\n",
    "# stride = tuple(np.arange(1,2,1, dtype= np.int))\n",
    "# padding = tuple(np.arange(1,2,1, dtype= np.int))\n",
    "# learning_rate = tuple(np.arange(0.01,0.02, 0.01, dtype= np.int))\n",
    "# n_epochs = tuple(np.arange(1,2, 1, dtype= np.int))\n",
    "\n",
    "# define the dictionary for GPyOpt\n",
    "domain = [{'name': 'kernel_sizes', 'type': 'discrete', 'domain': kernel_sizes},\n",
    "            {'name': 'stride', 'type': 'discrete', 'domain': stride},\n",
    "            {'name': 'padding', 'type': 'discrete', 'domain': padding},\n",
    "            {'name': 'learning_rate', 'type': 'discrete', 'domain': learning_rate},\n",
    "            {'name': 'n_epochs', 'type': 'discrete', 'domain': n_epochs},\n",
    "            ]\n",
    "\n",
    "# TODO Figure out how to represent the learning_rate as a float. Not sure the type should be discrete\n",
    "\n",
    "def objective_function(x): \n",
    "    # print(x)\n",
    "    param = x[0]\n",
    "        \n",
    "    loss = CNN_model_train(kernel_size = int(param[0]), \n",
    "                            stride = int(param[1]), padding = int(param[2]), \n",
    "                            learning_rate = param[3], n_epochs = int(param[4]))\n",
    "    \n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### EI acquisition function ###\n",
    "acquisition_func = \"EI\"\n",
    "\n",
    "opt = GPyOpt.methods.BayesianOptimization(f = objective_function,   # function to optimize\n",
    "                                              domain = domain,         # box-constrains of the problem\n",
    "                                              acquisition_type = acquisition_func      # Select acquisition function MPI, EI, LCB\n",
    "                                             )\n",
    "opt.acquisition.exploration_weight=.1\n",
    "\n",
    "opt.run_optimization(max_iter = 10) \n",
    "\n",
    "x_best = opt.X[np.argmin(opt.Y)]\n",
    "\n",
    "end = timer()\n",
    "print(\"For acquisition_type: {0}\".format(acquisition_func))\n",
    "print(\"time: {0}\".format(end - start))\n",
    "print(\"The best parameters obtained: {0}\".format(x_best))\n",
    "print(\"The loss was: {0}\".format(min(opt.Y)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### MPI acquisition function ###\n",
    "acquisition_func = \"MPI\"\n",
    "\n",
    "opt = GPyOpt.methods.BayesianOptimization(f = objective_function,   # function to optimize\n",
    "                                              domain = domain,         # box-constrains of the problem\n",
    "                                              acquisition_type = acquisition_func      # Select acquisition function MPI, EI, LCB\n",
    "                                             )\n",
    "opt.acquisition.exploration_weight=.1\n",
    "\n",
    "opt.run_optimization(max_iter = 10) \n",
    "\n",
    "x_best = opt.X[np.argmin(opt.Y)]\n",
    "\n",
    "end = timer()\n",
    "print(\"For acquisition_type: {0}\".format(acquisition_func))\n",
    "print(\"time: {0}\".format(end - start))\n",
    "print(\"The best parameters obtained: {0}\".format(x_best))\n",
    "print(\"The loss was: {0}\".format(min(opt.Y)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### MPI acquisition function ###\n",
    "acquisition_func = \"LCB\"\n",
    "\n",
    "opt = GPyOpt.methods.BayesianOptimization(f = objective_function,   # function to optimize\n",
    "                                              domain = domain,         # box-constrains of the problem\n",
    "                                              acquisition_type = acquisition_func      # Select acquisition function MPI, EI, LCB\n",
    "                                             )\n",
    "opt.acquisition.exploration_weight=.1\n",
    "\n",
    "opt.run_optimization(max_iter = 10) \n",
    "\n",
    "x_best = opt.X[np.argmin(opt.Y)]\n",
    "\n",
    "end = timer()\n",
    "print(\"For acquisition_type: {0}\".format(acquisition_func))\n",
    "print(\"time: {0}\".format(end - start))\n",
    "print(\"The best parameters obtained: {0}\".format(x_best))\n",
    "print(\"The loss was: {0}\".format(min(opt.Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0bf3d326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.77069855],\n",
       "       [27.7038784 ],\n",
       "       [15.90824223],\n",
       "       [23.49349022],\n",
       "       [ 2.42295766],\n",
       "       [ 3.53436947],\n",
       "       [ 6.69079113],\n",
       "       [ 7.11957741],\n",
       "       [ 5.53491402],\n",
       "       [ 3.18432856],\n",
       "       [22.96399117],\n",
       "       [ 2.30353451],\n",
       "       [ 5.62822676]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9fd78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
