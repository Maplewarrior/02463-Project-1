{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2cbeec",
   "metadata": {},
   "source": [
    "## See the ReadME for a description of the project\n",
    "\n",
    "\n",
    "### Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2905840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e68c130",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fa20980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (60000, 784) Test data shape: (10000, 784)\n",
      "Train labels shape: (60000,)   Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# define number of classes\n",
    "n_classes = 10\n",
    "\n",
    "# load train and test sets\n",
    "train = pd.read_csv('Data/fashion-mnist_train.csv')\n",
    "test = pd.read_csv('Data/fashion-mnist_test.csv')\n",
    "\n",
    "train = train.to_numpy()\n",
    "test = test.to_numpy()\n",
    "\n",
    "X_train = train[:,1:]\n",
    "y_train = train[:,0]\n",
    "X_test = test[:,1:]\n",
    "y_test = test[:,0]\n",
    "print(\"Train data shape:\", X_train.shape, \"Test data shape:\", X_test.shape)\n",
    "print(\"Train labels shape:\", y_train.shape,\"  Test labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f090f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([60000, 1, 28, 28]) Test data shape: torch.Size([10000, 1, 28, 28])\n",
      "Train labels shape: torch.Size([60000])   Test labels shape: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# this section is inspired by code from the article:\n",
    "# \"Build an Image Classification Model using Convolutional Neural Networks in PyTorch\"\n",
    "# Author: Pulkit Sharma\n",
    "# https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/\n",
    "\n",
    "# change training and test set into tensors\n",
    "X_train = X_train.reshape(len(X_train),1,28,28)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_train = X_train.type(torch.FloatTensor)\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_train = y_train.type(torch.LongTensor)\n",
    "\n",
    "X_test = X_test.reshape(len(X_test),1,28,28)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "X_test = X_test.type(torch.FloatTensor)\n",
    "\n",
    "y_test = y_test.astype(int)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "y_test = y_test.type(torch.LongTensor)\n",
    "\n",
    "# verify shape of training data\n",
    "print(\"Train data shape:\", X_train.shape, \"Test data shape:\", X_test.shape)\n",
    "print(\"Train labels shape:\", y_train.shape,\"  Test labels shape:\", y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5e4ca9",
   "metadata": {},
   "source": [
    "## Implementing the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e98d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section is inspired by code from the article:\n",
    "# \"Build an Image Classification Model using Convolutional Neural Networks in PyTorch\"\n",
    "# Author: Pulkit Sharma\n",
    "# https://www.analyticsvidhya.com/blog/2019/10/building-image-classification-models-cnn-pytorch/\n",
    "\n",
    "\n",
    "class Net(Module):\n",
    "    def __init__(self, kernel_size = 2, stride = 1, padding = 1):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        self.cnn_layers = Sequential(\n",
    "            # Define convolutional layers\n",
    "            # input dimensionality before each layer is added\n",
    "            \n",
    "            # 1st layer\n",
    "            # 1x28x28\n",
    "            Conv2d(1,4,kernel_size=kernel_size,stride=stride,padding=padding),\n",
    "            # apply batch normalization\n",
    "            #BatchNorm2d(4),\n",
    "            # activation function ReLU\n",
    "            ReLU(),\n",
    "            # apply pooling\n",
    "            MaxPool2d(kernel_size=kernel_size,stride=stride),\n",
    "            \n",
    "            # second layer\n",
    "            # 4x14x14\n",
    "            Conv2d(4,4,kernel_size=kernel_size,stride=stride,padding=padding),\n",
    "            #BatchNorm2d(4),\n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=kernel_size,stride=stride),\n",
    "            \n",
    "            # 4x7x7\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(4*7*7,n_classes)\n",
    "        )\n",
    "    \n",
    "    def update_linear_layers(self,input_size):\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(input_size,n_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        self.update_linear_layers(x.size()[1])\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c0cd82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, train_losses, val_losses, criterion):\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    # getting the training set\n",
    "    x_train_t, y_train_t = Variable(X_train), Variable(y_train)\n",
    "    # getting the validation set\n",
    "    x_val_t, y_val_t = Variable(X_test), Variable(y_test)\n",
    "    # converting the data into GPU format\n",
    "    if torch.cuda.is_available():\n",
    "        x_train_t = x_train_t.cuda()\n",
    "        y_train_t = y_train_t.cuda()\n",
    "        x_val_t = x_val_t.cuda()\n",
    "        y_val_t = y_val_t.cuda()\n",
    "\n",
    "    # clearing the Gradients of the model parameters\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # prediction for training and validation set\n",
    "    output_train = model(x_train_t)\n",
    "    output_val = model(x_val_t)\n",
    "\n",
    "    # computing the training and validation loss\n",
    "    loss_train = criterion(output_train, y_train_t)\n",
    "    loss_val = criterion(output_val, y_val_t)\n",
    "    train_losses.append(loss_train)\n",
    "    val_losses.append(loss_val)\n",
    "\n",
    "    # computing the updated weights of all the model parameters\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    tr_loss = loss_train.item()\n",
    "    if epoch%2 == 0:\n",
    "        # printing the validation loss\n",
    "        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)\n",
    "\n",
    "    return train_losses, val_losses, optimizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ecac926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CNN_model_train(kernel_size = 2, stride = 1, padding = 1, learning_rate = 0.07, n_epochs = 5):\n",
    "    \"\"\"Define network and \n",
    "\n",
    "    Args:\n",
    "        kernel_size (int, optional): _description_. Defaults to 2.\n",
    "        stride (int, optional): _description_. Defaults to 1.\n",
    "        padding (int, optional): _description_. Defaults to 1.\n",
    "        learning_rate (float, optional): _description_. Defaults to 0.07.\n",
    "        n_epochs (int, optional): _description_. Defaults to 5.\n",
    "    \"\"\"\n",
    "    # define model\n",
    "    model = Net(kernel_size, stride, padding)\n",
    "    # defining the optimizer\n",
    "    optimizer = Adam(model.parameters(), lr=0.07)\n",
    "    # defining the loss function\n",
    "    criterion = CrossEntropyLoss()\n",
    "    # checking if GPU is available\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    # defining the number of epochs\n",
    "    # n_epochs = 5\n",
    "    # empty list to store training losses\n",
    "    train_losses = []\n",
    "    # empty list to store validation losses\n",
    "    val_losses = []\n",
    "    # training the model\n",
    "    for epoch in range(n_epochs):\n",
    "        train_losses, val_losses, optimizer, model = train(epoch, model, optimizer, train_losses, val_losses, criterion)\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f3ff127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  1 \t loss : tensor(29.7087, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "CNN_model_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f416c",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e90a40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3d326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
